"""ì‚¬ì´ë“œë°” UI ëª¨ë“ˆ - íŒŒì¼ ì—…ë¡œë“œ ë° ì„ íƒ

ì„±ëŠ¥ ìµœì í™”:
- íŒŒì¼ ì²˜ë¦¬ í›„ ì¦‰ì‹œ ë©”ëª¨ë¦¬ í•´ì œ
- ìºì‹œ ë¬´íš¨í™”ë¡œ ë©”ëª¨ë¦¬ ê´€ë¦¬
- ì„¸ì…˜ ì§€ì†ì„±ì„ ìœ„í•œ ë¡œì»¬ìŠ¤í† ë¦¬ì§€ ì—°ë™
"""

import gc
import time
import json
from datetime import date, datetime, timedelta
import streamlit as st
import hashlib
from concurrent.futures import ThreadPoolExecutor, as_completed
from modules.pdf_parser import CareRecordParser
from modules.database import save_parsed_data, get_customers_with_records, get_all_records_by_date_range
from modules.ui.ui_helpers import (
    get_active_doc, get_person_keys_for_doc, iter_person_entries, 
    ensure_active_person, person_checkbox_key, select_person,
    get_person_done, set_person_done, invalidate_person_cache,
    iter_db_person_entries
)


def _get_current_month_range():
    """í˜„ì¬ ë‹¬ì˜ ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ ë°˜í™˜"""
    today = date.today()
    first_day = today.replace(day=1)
    if today.month == 12:
        last_day = today.replace(year=today.year + 1, month=1, day=1) - timedelta(days=1)
    else:
        last_day = today.replace(month=today.month + 1, day=1) - timedelta(days=1)
    return first_day, last_day


def _get_last_week_range():
    """ì €ë²ˆì£¼ ì›”ìš”ì¼ ~ ì¼ìš”ì¼ ë°˜í™˜"""
    today = date.today()
    # ì˜¤ëŠ˜ì˜ ìš”ì¼ (0=ì›”, 6=ì¼)
    current_weekday = today.weekday()
    # ì´ë²ˆì£¼ ì›”ìš”ì¼
    this_monday = today - timedelta(days=current_weekday)
    # ì €ë²ˆì£¼ ì›”ìš”ì¼
    last_monday = this_monday - timedelta(days=7)
    # ì €ë²ˆì£¼ ì¼ìš”ì¼
    last_sunday = last_monday + timedelta(days=6)
    return last_monday, last_sunday


def _restore_session_from_storage():
    """ë¡œì»¬ìŠ¤í† ë¦¬ì§€ì—ì„œ ë‚ ì§œ í•„í„° ë³µì› ë° ìë™ ì¡°íšŒ"""
    if 'session_restored' not in st.session_state:
        st.session_state.session_restored = True
        st.session_state.auto_search_pending = True


def _check_auto_search():
    """ìƒˆë¡œê³ ì¹¨ ì‹œ ì €ì¥ëœ ë‚ ì§œë¡œ ìë™ ì¡°íšŒ ì‹¤í–‰"""
    if st.session_state.get('auto_search_pending') and not st.session_state.docs:
        st.session_state.auto_search_pending = False
        # ì„¸ì…˜ì— ë‚ ì§œê°€ ìˆìœ¼ë©´ ìë™ ì¡°íšŒ
        if st.session_state.get('db_filter_start') and st.session_state.get('db_filter_end'):
            start_date = st.session_state.db_filter_start
            end_date = st.session_state.db_filter_end
            _execute_db_search(start_date, end_date)


def _update_filter_from_parsed_data(parsed_data):
    """PDF íŒŒì‹± ë°ì´í„°ì—ì„œ ë‚ ì§œ ë²”ìœ„ë¥¼ ì¶”ì¶œí•˜ì—¬ í•„í„°ì— ë°˜ì˜"""
    if not parsed_data:
        return
    
    dates = []
    for record in parsed_data:
        record_date = record.get('date')
        if record_date:
            # ë¬¸ìì—´ì´ë©´ dateë¡œ ë³€í™˜
            if isinstance(record_date, str):
                try:
                    from datetime import datetime as dt
                    record_date = dt.strptime(record_date, '%Y-%m-%d').date()
                except:
                    continue
            dates.append(record_date)
    
    if dates:
        min_date = min(dates)
        max_date = max(dates)
        st.session_state['db_filter_start'] = min_date
        st.session_state['db_filter_end'] = max_date


def _save_session_to_storage():
    """ì„¸ì…˜ ë°ì´í„°ë¥¼ ë¡œì»¬ìŠ¤í† ë¦¬ì§€ì— ì €ì¥ (JavaScript ì—°ë™)"""
    # ë‚ ì§œ í•„í„° ê°’ ì €ì¥
    start_date = st.session_state.get('db_filter_start', '')
    end_date = st.session_state.get('db_filter_end', '')
    start_str = str(start_date) if start_date else ''
    end_str = str(end_date) if end_date else ''
    
    # ë¡œì»¬ìŠ¤í† ë¦¬ì§€ì— ë‚ ì§œ í•„í„° ì €ì¥
    st.markdown(f"""
    <script>
    (function() {{
        localStorage.setItem('arisa_filter_start', '{start_str}');
        localStorage.setItem('arisa_filter_end', '{end_str}');
    }})();
    </script>
    """, unsafe_allow_html=True)


def render_sidebar():
    """ì‚¬ì´ë“œë°” ë Œë”ë§"""
    # ì„¸ì…˜ ë³µì› ì‹œë„
    _restore_session_from_storage()
    
    # ìë™ ì¡°íšŒ ì²´í¬ (ìƒˆë¡œê³ ì¹¨ ì‹œ)
    _check_auto_search()
    
    with st.sidebar:
        nav = st.radio(
            "ë©”ë‰´",
            options=["íŒŒì¼ ì²˜ë¦¬", "ìˆ˜ê¸‰ì ê´€ë¦¬", "ëŒ€ì‹œë³´ë“œ"],
            index=0,
            horizontal=True,
            key="sidebar_nav_app",
        )
        if nav == "ìˆ˜ê¸‰ì ê´€ë¦¬":
            st.switch_page("pages/customer_manage.py")
        elif nav == "ëŒ€ì‹œë³´ë“œ":
            st.switch_page("pages/dashboard.py")

        st.header("ğŸ“‚ íŒŒì¼ ì²˜ë¦¬")

        # 1. íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜
        uploaded_files = st.file_uploader(
            "ì¥ê¸°ìš”ì–‘ê¸‰ì—¬ ì œê³µê¸°ë¡ì§€ PDF ì—…ë¡œë“œ",
            type=["pdf"],
            accept_multiple_files=True,
            key="pdf_uploader"
        )

        if uploaded_files:
            newly_added_id = None
            for f in uploaded_files:
                file_bytes = f.getvalue()
                # íŒŒì¼ ë‚´ìš© ê¸°ë°˜ í•´ì‹œ ìƒì„± (ì¤‘ë³µ ë°©ì§€)
                file_id_source = f"{f.name}\0".encode("utf-8") + file_bytes
                file_id = hashlib.sha256(file_id_source).hexdigest()[:16]

                # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” íŒŒì¼ì¸ì§€ í™•ì¸
                exists = any(d.get("id") == file_id for d in st.session_state.docs)

                if not exists:
                    try:
                        # íŒŒì‹± ì‹œì‘ ì‹œê°„ ê¸°ë¡
                        start_time = time.time()
                        status_placeholder = st.empty()
                        
                        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ íŒŒì‹± ì‹¤í–‰
                        from concurrent.futures import ThreadPoolExecutor, wait
                        import threading
                        
                        parser = CareRecordParser(f)
                        parsed = None
                        parsing_done = threading.Event()
                        
                        def do_parse():
                            nonlocal parsed
                            parsed = parser.parse()
                            parsing_done.set()
                        
                        with ThreadPoolExecutor(max_workers=1) as executor:
                            future = executor.submit(do_parse)
                            
                            # ì‹¤ì‹œê°„ ê²½ê³¼ ì‹œê°„ í‘œì‹œ
                            while not parsing_done.is_set():
                                elapsed = time.time() - start_time
                                status_placeholder.info(f"ğŸ“„ {f.name} íŒŒì‹± ì¤‘... ({elapsed:.1f}ì´ˆ)")
                                time.sleep(0.5)
                            
                            future.result()  # ì˜ˆì™¸ ë°œìƒ ì‹œ ì „íŒŒ
                        
                        # íŒŒì‹± ì™„ë£Œ ì‹œê°„ ê³„ì‚°
                        elapsed_time = time.time() - start_time
                        total_records = len(parsed)
                        
                        # ì™„ë£Œ ë©”ì‹œì§€ í‘œì‹œ
                        status_placeholder.empty()
                        
                        # íŒŒì‹± í›„ íŒŒì„œ ê°ì²´ í•´ì œ
                        del parser
                        gc.collect()

                        new_doc = {
                            "id": file_id,
                            "name": f.name,
                            "completed": False,
                            "parsed_data": parsed,
                            "eval_results": {},
                            "error": None,
                        }
                        st.session_state.docs.append(new_doc)
                        newly_added_id = file_id
                        
                        # PDF ë°ì´í„°ì—ì„œ ë‚ ì§œ ë²”ìœ„ ì¶”ì¶œí•˜ì—¬ í•„í„°ì— ë°˜ì˜
                        _update_filter_from_parsed_data(parsed)
                        
                        # íŒŒì‹± ì™„ë£Œ ë©”ì‹œì§€ë¥¼ session_stateì— ì €ì¥
                        st.session_state.parsing_success = f"{total_records}ê±´ ë°ì´í„° ì¡°íšŒ ({elapsed_time:.1f}ì´ˆ)"

                    except Exception as e:
                        st.error(f"{f.name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                        st.session_state.docs.append({
                            "id": file_id,
                            "name": f.name,
                            "completed": False,
                            "parsed_data": [],
                            "error": str(e),
                        })

            # ìƒˆë¡œ ì¶”ê°€ëœ íŒŒì¼ì´ ìˆìœ¼ë©´ ê·¸ íŒŒì¼ë¡œ ìë™ ì „í™˜
            if newly_added_id:
                st.session_state.active_doc_id = newly_added_id
                st.session_state.active_person_key = None
                st.rerun()

        # íŒŒì‹± ì™„ë£Œ ë©”ì‹œì§€ í‘œì‹œ
        if 'parsing_success' in st.session_state:
            st.success(st.session_state.parsing_success)
            del st.session_state.parsing_success

        st.divider()
        
        # ğŸ“… ê¸°ê°„ë³„ ë°ì´í„° ì¡°íšŒ - í•­ìƒ í‘œì‹œ
        _render_date_filter_section()


        if st.session_state.docs:
            if not st.session_state.active_doc_id:
                st.session_state.active_doc_id = st.session_state.docs[0]["id"]

            active_doc = get_active_doc()
            
            # PDF ì—…ë¡œë“œëœ ê²½ìš°ì—ë§Œ íŒŒì¼ëª… í‘œì‹œ
            if active_doc and not active_doc.get('is_db_source'):
                st.subheader("ğŸ“„ í˜„ì¬ íŒŒì¼")
                st.write(f"**{active_doc['name']}**")

            if active_doc and active_doc.get("parsed_data"):
                # Auto-save all parsed data to DB (only once)
                if not active_doc.get("db_saved"):
                    with st.spinner("DB ìë™ ì €ì¥ ì¤‘..."):
                        count = save_parsed_data(active_doc["parsed_data"])
                        if count > 0:
                            st.toast(f"{count}ê±´ì˜ ê¸°ë¡ì´ ìë™ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.", icon="âœ…")
                            for doc in st.session_state.docs:
                                if doc["id"] == active_doc["id"]:
                                    doc["db_saved"] = True
                                    break

            # Batch AI Processing buttons
            person_entries = iter_person_entries()
            if person_entries:
                st.divider()
                st.markdown("#### ì „ì²´ì¸ì› AI ì²˜ë¦¬")
                
                st.markdown("""
                <style>
                .green-text {
                    color: #00C851 !important;
                }
                </style>
                """, unsafe_allow_html=True)
                
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("ì£¼ê°„ ìƒíƒœ ë³€í™” ê¸°ë¡ ìƒì„±",
                               use_container_width=True, 
                               help="ì „ì²´ ì¸ì›ì˜ ì£¼ê°„ ìƒíƒœë³€í™” ê¸°ë¡ì§€ë¥¼ ì¼ê´„ ìƒì„±í•©ë‹ˆë‹¤"):
                        _batch_generate_weekly_reports(person_entries)
                with col2:
                    if st.button("ì¼ì¼ íŠ¹ì´ì‚¬í•­ í‰ê°€",
                               use_container_width=True,
                               help="ì „ì²´ ì¸ì›ì˜ íŠ¹ì´ì‚¬í•­ì„ ì¼ê´„ í‰ê°€í•©ë‹ˆë‹¤"):
                        _batch_evaluate_all_optimized(person_entries)

            # í”„ë˜ê·¸ë¨¼íŠ¸ë¡œ ì‚¬ëŒ ëª©ë¡ ë Œë”ë§ (ë¶€ë¶„ ë¦¬ë Œë”ë§ ìµœì í™”)
            _render_person_list_fragment()
            
            # ì„¸ì…˜ ë°ì´í„° ì €ì¥
            _save_session_to_storage()


@st.fragment
def _render_person_list_fragment():
    """ì‚¬ëŒ ëª©ë¡ ë Œë”ë§ (í”„ë˜ê·¸ë¨¼íŠ¸ë¡œ ë¶€ë¶„ ë¦¬ë Œë”ë§ ìµœì í™”)
    
    @st.fragment: ì´ ì»´í¬ë„ŒíŠ¸ë§Œ ë…ë¦½ì ìœ¼ë¡œ ë¦¬ë Œë”ë§ë˜ì–´ ì „ì²´ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ ë°©ì§€
    """
    person_entries = iter_person_entries()
    person_count = len(person_entries)
    st.subheader(f"ğŸ‘¥ ì „ì²´ {person_count}ëª…")
    
    if not person_entries:
        st.info("íŒŒì‹±ëœ ì¸ì›ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    st.caption("ì´ë¦„ì„ ì„ íƒí•˜ë©´ ìƒì„¸ ê¸°ë¡ì´ í‘œì‹œë©ë‹ˆë‹¤.")
    active_person_key = ensure_active_person()
    
    for entry in person_entries:
        is_active = entry["key"] == active_person_key
        cols = st.columns([0.75, 0.25])
        display_label = f"{entry['person_name']} Â· {entry['record_count']}ê±´"
        button_type = "primary" if is_active else "secondary"
        
        with cols[0]:
            if st.button(
                display_label,
                key=f"person_btn_{entry['key']}",
                type=button_type,
                use_container_width=True
            ):
                select_person(entry["key"], entry["doc_id"])
                st.rerun()
        
        with cols[1]:
            done_value = st.checkbox(
                "ì™„ë£Œ",
                value=get_person_done(entry["key"]),
                key=f"done_{entry['key']}"
            )
            set_person_done(entry["key"], done_value)


def _render_person_date_filter(entry):
    """ì„ íƒëœ ëŒ€ìƒìì˜ ë‚ ì§œ í•„í„° ë Œë”ë§"""
    person_name = entry.get('person_name', 'ëŒ€ìƒì')
    
    with st.expander(f"ğŸ“… {person_name} ì–´ë¥´ì‹  ê¸°ê°„ í•„í„°", expanded=False):
        default_start, default_end = _get_current_month_range()
        
        # ëŒ€ìƒìë³„ ë‚ ì§œ í•„í„° ì„¸ì…˜ í‚¤
        person_start_key = f"person_filter_start_{entry['key']}"
        person_end_key = f"person_filter_end_{entry['key']}"
        
        if person_start_key not in st.session_state:
            st.session_state[person_start_key] = default_start
        if person_end_key not in st.session_state:
            st.session_state[person_end_key] = default_end
        
        col1, col2 = st.columns(2)
        with col1:
            p_start = st.date_input(
                "ì‹œì‘",
                value=st.session_state[person_start_key],
                key=f"p_start_{entry['key']}"
            )
        with col2:
            p_end = st.date_input(
                "ì¢…ë£Œ",
                value=st.session_state[person_end_key],
                key=f"p_end_{entry['key']}"
            )
        
        st.session_state[person_start_key] = p_start
        st.session_state[person_end_key] = p_end
        
        if st.button(f"ğŸ” {person_name} ì¡°íšŒ", use_container_width=True, key=f"p_search_{entry['key']}"):
            _execute_person_db_search(entry, p_start, p_end)


def _execute_person_db_search(entry, start_date, end_date):
    """íŠ¹ì • ëŒ€ìƒìì˜ DB ë°ì´í„° ì¡°íšŒ"""
    from modules.database import get_all_records_by_date_range
    
    person_name = entry.get('person_name')
    
    try:
        records = get_all_records_by_date_range(start_date, end_date)
        
        # í•´ë‹¹ ëŒ€ìƒìì˜ ë ˆì½”ë“œë§Œ í•„í„°ë§
        person_records = [r for r in records if r.get('customer_name') == person_name]
        
        if person_records:
            db_doc_id = f"db_person_{person_name}_{start_date}_{end_date}"
            
            # ê¸°ì¡´ ê°œì¸ ì¡°íšŒ ë¬¸ì„œ ì œê±°
            st.session_state.docs = [d for d in st.session_state.docs 
                                      if not d.get('id', '').startswith(f'db_person_{person_name}_')]
            
            parsed_records = _convert_db_records(person_records)
            
            new_doc = {
                "id": db_doc_id,
                "name": f"{person_name} ({start_date} ~ {end_date})",
                "completed": False,
                "parsed_data": parsed_records,
                "eval_results": {},
                "error": None,
                "db_saved": True,
                "is_db_source": True,
            }
            st.session_state.docs.append(new_doc)
            st.session_state.active_doc_id = db_doc_id
            st.session_state.active_person_key = f"{db_doc_id}::{person_name}"
            
            invalidate_person_cache()
            
            st.toast(f"âœ… {person_name} ì–´ë¥´ì‹  {len(parsed_records)}ê±´ ì¡°íšŒ", icon="âœ…")
            st.rerun()
        else:
            st.warning(f"í•´ë‹¹ ê¸°ê°„ì— {person_name} ì–´ë¥´ì‹ ì˜ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        st.error(f"ì¡°íšŒ ì˜¤ë¥˜: {e}")


def _batch_generate_weekly_reports(person_entries):
    """ì „ì²´ ì¸ì›ì˜ ì£¼ê°„ ìƒíƒœë³€í™” ê¸°ë¡ì§€ë¥¼ ì¼ê´„ ìƒì„±í•©ë‹ˆë‹¤."""
    if not person_entries:
        st.warning("ì²˜ë¦¬í•  ì¸ì›ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    total = len(person_entries)
    
    for i, entry in enumerate(person_entries):
        status_text.text(f"{entry['person_name']} ì§„í–‰ì¤‘ ({i+1}/{total})")
        
        # Get person records
        doc = next((d for d in st.session_state.docs if d["id"] == entry["doc_id"]), None)
        if not doc:
            continue
            
        person_records = [
            r for r in doc.get("parsed_data", [])
            if (r.get("customer_name") or "ë¯¸ìƒ") == entry["person_name"]
        ]
        
        if not person_records:
            continue
            
        # Resolve customer_id
        from modules.customers import resolve_customer_id
        customer_id = (person_records[0].get("customer_id") if person_records else None)
        if customer_id is None:
            try:
                customer_id = resolve_customer_id(
                    name=entry["person_name"],
                    recognition_no=(person_records[0].get("customer_recognition_no") if person_records else None),
                    birth_date=(person_records[0].get("customer_birth_date") if person_records else None),
                )
            except Exception:
                customer_id = None
        
        if customer_id is None:
            continue
        
        # Compute weekly status
        from modules.weekly_data_analyzer import compute_weekly_status
        week_dates = sorted([r.get("date") for r in person_records if r.get("date")])
        if not week_dates:
            continue
            
        week_start = week_dates[-1]
        result = compute_weekly_status(entry["person_name"], week_start, customer_id)
        
        if result.get("error") or not result.get("scores"):
            continue
            
        # Generate AI report
        from modules.services.weekly_report_service import report_service
        from modules.database import save_weekly_status
        prev_range, curr_range = result["ranges"]
        ai_payload = result.get("trend", {}).get("ai_payload")
        
        if ai_payload:
            try:
                report = report_service.generate_weekly_report(
                    entry["person_name"],
                    (prev_range[0], curr_range[1]),
                    ai_payload,
                )
                
                if not isinstance(report, dict) or not report.get("error"):
                    text_report = report if isinstance(report, str) else str(report)
                    save_weekly_status(
                        customer_id=customer_id,
                        start_date=prev_range[0],
                        end_date=curr_range[1],
                        report_text=text_report,
                    )
            except Exception:
                pass
        
        progress_bar.progress((i + 1) / total)
    
    status_text.text("âœ… ëª¨ë“  ì¸ì›ì˜ ì£¼ê°„ ìƒíƒœë³€í™” ê¸°ë¡ì§€ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.toast("âœ… ì¼ê´„ ì²˜ë¦¬ ì™„ë£Œ!", icon="âœ…")


def _batch_evaluate_all(person_entries):
    """ì „ì²´ ì¸ì›ì˜ íŠ¹ì´ì‚¬í•­ì„ ì¼ê´„ í‰ê°€í•©ë‹ˆë‹¤."""
    if not person_entries:
        st.warning("ì²˜ë¦¬í•  ì¸ì›ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    total = len(person_entries)
    
    for i, entry in enumerate(person_entries):
        status_text.text(f"{entry['person_name']} ì§„í–‰ì¤‘ ({i+1}/{total})")
        
        # Get person records from database
        try:
            from modules.db_connection import db_query
            from modules.services.daily_report_service import evaluation_service
            
            with db_query() as cursor:
                # Get customer_id first
                cursor.execute(
                    "SELECT customer_id FROM customers WHERE name = %s LIMIT 1",
                    (entry["person_name"],)
                )
                customer_result = cursor.fetchone()
                
                if not customer_result:
                    continue
                    
                customer_id = customer_result["customer_id"]
                
                # Get records for this customer
                cursor.execute(
                    """
                    SELECT di.record_id, c.name as customer_name, di.date, 
                           dp.note as physical_note, dc.note as cognitive_note, 
                           dn.note as nursing_note, dr.note as functional_note,
                           dp.writer_name as writer_physical, dc.writer_name as writer_cognitive, 
                           dn.writer_name as writer_nursing, dr.writer_name as writer_recovery
                    FROM daily_infos di
                    LEFT JOIN customers c ON di.customer_id = c.customer_id
                    LEFT JOIN daily_physicals dp ON dp.record_id = di.record_id
                    LEFT JOIN daily_cognitives dc ON dc.record_id = di.record_id
                    LEFT JOIN daily_nursings dn ON dn.record_id = di.record_id
                    LEFT JOIN daily_recoveries dr ON dr.record_id = di.record_id
                    WHERE di.customer_id = %s
                    ORDER BY di.date DESC
                    """,
                    (customer_id,)
                )
                
                records = []
                for row in cursor.fetchall():
                    records.append({
                        "record_id": row["record_id"],
                        "customer_name": row["customer_name"],
                        "date": row["date"],
                        "physical_note": row["physical_note"],
                        "cognitive_note": row["cognitive_note"],
                        "nursing_note": row["nursing_note"],
                        "functional_note": row["functional_note"],
                        "writer_physical": row["writer_physical"],
                        "writer_cognitive": row["writer_cognitive"],
                        "writer_nursing": row["writer_nursing"],
                        "writer_recovery": row["writer_recovery"]
                    })
            
            # Evaluate all records for this person using process_daily_note_evaluation
            # íŠ¹ì´ì‚¬í•­ í‰ê°€ëŠ” PHYSICALê³¼ COGNITIVEë§Œ ìˆ˜í–‰
            for record in records:
                categories = [
                    ("PHYSICAL", record.get("physical_note", ""), record.get("writer_physical")),
                    ("COGNITIVE", record.get("cognitive_note", ""), record.get("writer_cognitive"))
                ]
                
                for category, text, category_writer in categories:
                    # ë¹ˆ í…ìŠ¤íŠ¸ëŠ” ê±´ë„ˆë›°ê¸°
                    if not text or text.strip() in ['íŠ¹ì´ì‚¬í•­ ì—†ìŒ', 'ê²°ì„', '']:
                        continue
                    
                    note_writer_id = record.get(f"writer_{category.lower()}_id", 1)
                    
                    evaluation_service.process_daily_note_evaluation(
                        record_id=record["record_id"],
                        category=category,
                        note_text=text,
                        note_writer_user_id=note_writer_id,
                        writer=category_writer or "",
                        customer_name=record.get("customer_name", ""),
                        date=record.get("date", "")
                    )
            
        except Exception as e:
            st.error(f"{entry['person_name']} í‰ê°€ ì¤‘ ì˜¤ë¥˜: {e}")
        
        progress_bar.progress((i + 1) / total)
    
    status_text.text("âœ… ëª¨ë“  ì¸ì›ì˜ íŠ¹ì´ì‚¬í•­ í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.toast("âœ… ì¼ê´„ í‰ê°€ ì™„ë£Œ!", icon="âœ…")
    st.rerun()


def _batch_evaluate_all_optimized(person_entries):
    """ì„±ëŠ¥ ìµœì í™”ëœ ì „ì²´ ì¸ì› íŠ¹ì´ì‚¬í•­ ì¼ê´„ í‰ê°€
    
    íƒ­ì˜ ë¹ ë¥¸ ë¡œì§ê³¼ ë™ì¼í•˜ê²Œ evaluate_special_note_with_aië¥¼ ì‚¬ìš©í•˜ì—¬
    1ë²ˆì˜ AI í˜¸ì¶œë¡œ ì‹ ì²´/ì¸ì§€ë¥¼ ë™ì‹œì— í‰ê°€í•©ë‹ˆë‹¤.
    """
    if not person_entries:
        st.warning("ì²˜ë¦¬í•  ì¸ì›ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    from modules.services.daily_report_service import evaluation_service
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # í˜„ì¬ active_docì—ì„œ ì „ì²´ ë ˆì½”ë“œ ìˆ˜ì§‘
    active_doc = get_active_doc()
    if not active_doc or not active_doc.get("parsed_data"):
        st.warning("í‰ê°€í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì „ì²´ ì¸ì› ê¸°ë¡ ìˆ˜ì§‘ (íƒ­ê³¼ ë™ì¼í•œ ë¡œì§)
    all_records = []
    for r in active_doc.get("parsed_data", []):
        if r.get("physical_note", "").strip() or r.get("cognitive_note", "").strip():
            # ì´ë¯¸ í‰ê°€ëœ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸ (ì¤‘ë³µ ìš”ì²­ ë°©ì§€)
            customer_name = r.get('customer_name', '')
            date_str = r.get('date', '')
            record_id = evaluation_service.get_record_id(customer_name, date_str)
            
            # DBì—ì„œ ì´ë¯¸ ì‹ ì²´/ì¸ì§€ í‰ê°€ê°€ ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸
            if record_id:
                phys_eval = evaluation_service.get_evaluation_from_db(record_id, 'SPECIAL_NOTE_PHYSICAL')
                cogn_eval = evaluation_service.get_evaluation_from_db(record_id, 'SPECIAL_NOTE_COGNITIVE')
                
                # ì´ë¯¸ í‰ê°€ê°€ ì™„ë£Œëœ ê±´ì€ ì œì™¸
                if phys_eval['grade'] != 'í‰ê°€ì—†ìŒ' and cogn_eval['grade'] != 'í‰ê°€ì—†ìŒ':
                    continue
                    
            all_records.append(r)
    
    if not all_records:
        st.success("ëª¨ë“  ê¸°ë¡ì´ ì´ë¯¸ í‰ê°€ë˜ì—ˆê±°ë‚˜ í‰ê°€í•  íŠ¹ì´ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    total = len(all_records)
    
    # ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ í•¨ìˆ˜ ì •ì˜ (íƒ­ê³¼ ë™ì¼í•œ ë¡œì§)
    def process_record(record):
        date_str = record.get("date", "ë‚ ì§œ ì—†ìŒ")
        customer_name = record.get('customer_name', '')
        physical_note = record.get("physical_note", "").strip()
        cognitive_note = record.get("cognitive_note", "").strip()
        
        try:
            print(f"DEBUG: Processing {customer_name} ({date_str})")
            
            # 1ë²ˆì˜ AI í˜¸ì¶œë¡œ ì‹ ì²´/ì¸ì§€ ë™ì‹œ í‰ê°€
            result = evaluation_service.evaluate_special_note_with_ai(record)
            if result:
                record_id = evaluation_service.get_record_id(customer_name, date_str)
                if record_id:
                    result_with_notes = result.copy()
                    result_with_notes['physical_note'] = physical_note
                    result_with_notes['cognitive_note'] = cognitive_note
                    evaluation_service.save_special_note_evaluation(record_id, result_with_notes)
            return True
        except Exception as e:
            print(f"Error processing {customer_name} ({date_str}): {str(e)}")
            return False

    max_workers = 4
    completed = 0
    
    # UI ì—…ë°ì´íŠ¸ìš© ì»¨í…Œì´ë„ˆ
    import concurrent.futures
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_record = {executor.submit(process_record, rec): rec for rec in all_records}
        for future in concurrent.futures.as_completed(future_to_record):
            try:
                future.result(timeout=40)
            except concurrent.futures.TimeoutError:
                print("DEBUG: Task timed out")
            except Exception as e:
                print(f"DEBUG: Task error: {e}")
            
            completed += 1
            progress_bar.progress(completed / total)
            status_text.text(f"â³ ì „ì²´ ì¸ì› í‰ê°€ ì§„í–‰ ì¤‘... ({completed}/{total})")
    
    st.success(f"ì´ {total}ê±´ì˜ íŠ¹ì´ì‚¬í•­ í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.toast("âœ… ì¼ê´„ í‰ê°€ ì™„ë£Œ!", icon="âœ…")
    st.rerun()


def _render_date_filter_section():
    """ğŸ“… ê¸°ê°„ë³„ ë°ì´í„° ì¡°íšŒ ì„¹ì…˜ - í•­ìƒ í‘œì‹œ"""
    st.subheader("ğŸ“… ê¸°ê°„ë³„ ë°ì´í„° ì¡°íšŒ")
    
    # ë‚ ì§œ í•„í„°ë§ (ë””í´íŠ¸: í˜„ì¬ ë‹¬)
    default_start, default_end = _get_current_month_range()
    
    # ìœ„ì ¯ í‚¤
    start_key = "db_filter_start"
    end_key = "db_filter_end"
    
    # ì´ˆê¸°ê°’ ì„¤ì •
    if start_key not in st.session_state:
        st.session_state[start_key] = default_start
    if end_key not in st.session_state:
        st.session_state[end_key] = default_end
    
    # ë²„íŠ¼ í´ë¦­ í”Œë˜ê·¸ í™•ì¸ ë° ê°’ ë³€ê²½ (ìœ„ì ¯ ìƒì„± ì „)
    if st.session_state.get('_set_last_week'):
        last_mon, last_sun = _get_last_week_range()
        st.session_state[start_key] = last_mon
        st.session_state[end_key] = last_sun
        del st.session_state['_set_last_week']
    
    if st.session_state.get('_set_prev_week'):
        current_start = st.session_state[start_key]
        current_monday = current_start - timedelta(days=current_start.weekday())
        prev_monday = current_monday - timedelta(days=7)
        prev_sunday = prev_monday + timedelta(days=6)
        st.session_state[start_key] = prev_monday
        st.session_state[end_key] = prev_sunday
        del st.session_state['_set_prev_week']
    
    col1, col2 = st.columns(2)
    with col1:
        st.date_input("ì‹œì‘ì¼", key=start_key)
    with col2:
        st.date_input("ì¢…ë£Œì¼", key=end_key)
    
    col_btn1, col_btn2, col_btn3 = st.columns(3)
    with col_btn1:
        if st.button("ì¡°íšŒ", use_container_width=True, key="db_search_btn"):
            _execute_db_search(st.session_state[start_key], st.session_state[end_key])
    with col_btn2:
        if st.button("1ì£¼ì „", use_container_width=True, key="db_prev_week_btn"):
            st.session_state['_set_prev_week'] = True
            st.rerun()
    with col_btn3:
        if st.button("ì§€ë‚œì£¼", use_container_width=True, key="db_last_week_btn"):
            st.session_state['_set_last_week'] = True
            st.rerun()

    # í˜„ì¬ ì¡°íšŒëœ ê¸°ê°„ í‘œì‹œ
    if st.session_state.get('db_records_loaded'):
        active_doc = get_active_doc()
        if active_doc and active_doc.get('is_db_source'):
            record_count = len(active_doc.get('parsed_data', []))
            st.caption(f"ì „ì²´ ë°ì´í„° ê°œìˆ˜: {record_count}ê±´")


def _execute_db_search(start_date, end_date):
    """DBì—ì„œ ì „ì²´ ë°ì´í„° ì¡°íšŒ ì‹¤í–‰"""
    try:
        records = get_all_records_by_date_range(start_date, end_date)
        
        if records:
            db_doc_id = f"db_{start_date}_{end_date}"
            
            # ê¸°ì¡´ DB ë¬¸ì„œê°€ ìˆìœ¼ë©´ ì œê±°
            st.session_state.docs = [d for d in st.session_state.docs if not d.get('id', '').startswith('db_')]
            
            # DB ë ˆì½”ë“œë¥¼ parsed_data í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            parsed_records = _convert_db_records(records)
            
            new_doc = {
                "id": db_doc_id,
                "name": f"DB ì¡°íšŒ ({start_date} ~ {end_date})",
                "completed": False,
                "parsed_data": parsed_records,
                "eval_results": {},
                "error": None,
                "db_saved": True,
                "is_db_source": True,
            }
            st.session_state.docs.append(new_doc)
            st.session_state.active_doc_id = db_doc_id
            st.session_state.active_person_key = None
            st.session_state.db_records_loaded = True
            
            # ìºì‹œ ë¬´íš¨í™”
            invalidate_person_cache()
            
            st.toast(f"âœ… {len(parsed_records)}ê±´ì˜ ê¸°ë¡ì„ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤.", icon="âœ…")
            st.rerun()
        else:
            st.toast(f"{start_date} ~ {end_date} ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.", icon="â„¹ï¸")
            
    except Exception as e:
        st.error(f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")


def _convert_db_records(records):
    """DB ë ˆì½”ë“œë¥¼ parsed_data í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    parsed_records = []
    for r in records:
        parsed_records.append({
            'customer_id': r.get('customer_id'),
            'customer_name': r.get('customer_name'),
            'customer_birth_date': r.get('customer_birth_date'),
            'customer_grade': r.get('customer_grade'),
            'customer_recognition_no': r.get('customer_recognition_no'),
            'record_id': r.get('record_id'),
            'date': r.get('date'),
            'start_time': r.get('start_time'),
            'end_time': r.get('end_time'),
            'total_service_time': r.get('total_service_time'),
            'transport_service': r.get('transport_service'),
            'transport_vehicles': r.get('transport_vehicles'),
            'hygiene_care': r.get('hygiene_care'),
            'bath_time': r.get('bath_time'),
            'bath_method': r.get('bath_method'),
            'meal_breakfast': r.get('meal_breakfast'),
            'meal_lunch': r.get('meal_lunch'),
            'meal_dinner': r.get('meal_dinner'),
            'toilet_care': r.get('toilet_care'),
            'mobility_care': r.get('mobility_care'),
            'physical_note': r.get('physical_note'),
            'writer_phy': r.get('writer_phy'),
            'cog_support': r.get('cog_support'),
            'comm_support': r.get('comm_support'),
            'cognitive_note': r.get('cognitive_note'),
            'writer_cog': r.get('writer_cog'),
            'bp_temp': r.get('bp_temp'),
            'health_manage': r.get('health_manage'),
            'nursing_manage': r.get('nursing_manage'),
            'emergency': r.get('emergency'),
            'nursing_note': r.get('nursing_note'),
            'writer_nur': r.get('writer_nur'),
            'prog_basic': r.get('prog_basic'),
            'prog_activity': r.get('prog_activity'),
            'prog_cognitive': r.get('prog_cognitive'),
            'prog_therapy': r.get('prog_therapy'),
            'prog_enhance_detail': r.get('prog_enhance_detail'),
            'functional_note': r.get('functional_note'),
            'writer_func': r.get('writer_func'),
        })
    return parsed_records
